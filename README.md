<div align="center">

# ğŸš€ KSdb

**A Production-Ready Vector Database for AI Applications**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com/)

[Features](#-features) â€¢ [Quick Start](#-quick-start) â€¢ [Benchmarks](#-benchmarks) â€¢ [Demo](#-demo-app) â€¢ [Deployment](#-deployment)

</div>

---

## ğŸ¯ What is KSdb?

KSdb is a **high-performance vector database** built from scratch with features that go beyond ChromaDB and Pinecone:

- âš¡ **5-7x faster** than ChromaDB (benchmarked)
- ğŸ” **Hybrid Search** (Vector + Keyword with RRF fusion)
- ğŸ§  **Knowledge Graph** extraction (auto-extract entities & relationships)
- ğŸ–¼ï¸ **OCR Support** (read scanned PDFs with EasyOCR)
- ğŸ¯ **Smart Deduplication** (similarity-based)
- ğŸš€ **GPU Acceleration** (CUDA, MPS, ROCm)
- ğŸŒ **MCP Server** (Cursor AI integration)

Perfect for **RAG systems**, **semantic search**, **AI agents**, and **document Q&A**.

---

## âœ¨ Features

| Feature | Status | Description |
|---------|--------|-------------|
| **Hybrid Search** | âœ… | Vector + FTS5 keyword search with RRF |
| **Knowledge Graph** | âœ… | Auto-extract entities & relationships |
| **GPU Acceleration** | âœ… | CUDA, MPS (Mac), ROCm support |
| **OCR** | âœ… | Read scanned PDFs with EasyOCR |
| **Smart Deduplication** | âœ… | Similarity-based duplicate detection |
| **Metadata Filtering** | âœ… | Advanced query filters ($and, $or, $gt, etc.) |
| **Python SDK** | âœ… | ChromaDB-compatible API |
| **REST API** | âœ… | FastAPI with auto docs |
| **MCP Server** | âœ… | Cursor AI integration |
| **Streamlit Demo** | âœ… | RAG chatbot with metrics |

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone the repo
git clone https://github.com/Kulraj69/KSDB.git
cd KSdb

# Install dependencies
pip install -e .

# Start the server
python -m ksdb.cli run
```

Server starts at `http://localhost:8000` ğŸ‰

### Python SDK

```python
from ksdb.client import Client

# Connect to KSdb
client = Client(url="http://localhost:8000")

# Create a collection
collection = client.get_or_create_collection("my_docs")

# Add documents (with auto-deduplication & graph extraction)
collection.add(
    ids=["doc1", "doc2", "doc3"],
    documents=[
        "KSdb is 5x faster than ChromaDB",
        "It supports hybrid search with keyword matching",
        "Built with GPU acceleration for speed"
    ],
    metadatas=[
        {"category": "performance"},
        {"category": "features"},
        {"category": "tech"}
    ],
    deduplicate=True,      # Auto-remove duplicates
    extract_graph=True     # Auto-extract knowledge graph
)

# Hybrid Search (Vector + Keyword)
results = collection.query(
    query_texts=["How fast is KSdb?"],
    n_results=3,
    where={"category": "performance"}  # Metadata filtering
)

print(results)
```

---

## ğŸ“Š Benchmarks

### KSdb vs ChromaDB (Pure Vector Search)

Tested on Mac M-series with 500 documents:

| Metric | KSdb | ChromaDB | Winner |
|--------|------|----------|--------|
| **Ingestion** | 3.28s | 17.33s | **KSdb 5.3x faster** âš¡ |
| **Retrieval** | 0.03s | 0.22s | **KSdb 7.1x faster** âš¡ |
| **Total RAG** | 1.91s | 1.91s | Tie ğŸ¤ |

**Key Advantage**: KSdb offers **Hybrid Search** (vector + keyword), which ChromaDB doesn't support!

### Run Benchmarks Yourself

```bash
export HF_TOKEN="your_huggingface_token"
python benchmark_fair_comparison.py
```

See detailed performance analysis: `python performance_analysis.py`

---

## ğŸ¨ Demo App

KSdb includes a **Streamlit RAG Demo** with OCR support:

```bash
# Set your Hugging Face token
export HF_TOKEN="your_token"

# Start KSdb server
python -m ksdb.cli run

# In another terminal, run the demo
streamlit run app.py
```

**Features:**
- ğŸ“„ Upload PDFs/TXT (with OCR for scanned docs)
- ğŸ’¬ ChatGPT-like interface
- ğŸ“Š Real-time metrics (retrieval + generation time)
- ğŸ§  Knowledge graph extraction
- ğŸ¯ Auto-deduplication

---

## ğŸ§  Knowledge Graph

KSdb auto-extracts entities and relationships using GLiNER:

```python
# Enable graph extraction
collection.add(
    ids=["doc1"],
    documents=["Apple Inc. was founded by Steve Jobs in California"],
    extract_graph=True
)

# Query the knowledge graph
graph = collection.get_graph(subjects=["Apple Inc."])
# Returns: [
#   {"subject": "Apple Inc.", "predicate": "founded_by", "object": "Steve Jobs"},
#   {"subject": "Apple Inc.", "predicate": "located_in", "object": "California"}
# ]
```

---

## ğŸ” Hybrid Search

Unlike pure vector databases, KSdb combines:
1. **Vector Search** (semantic similarity)
2. **Keyword Search** (exact matches using FTS5)
3. **RRF Fusion** (Reciprocal Rank Fusion for best results)

This gives **better accuracy** for real-world queries!

---

## ğŸš€ Hardware Acceleration

KSdb automatically uses your GPU:

```bash
# Mac (M-series)
ğŸš€ Hardware Acceleration: MPS (Mac GPU) Enabled

# NVIDIA
ğŸš€ Hardware Acceleration: CUDA (NVIDIA GPU) Enabled

# AMD ROCm
ğŸš€ Hardware Acceleration: ROCm (AMD GPU) Enabled
```

**Performance**: 5-10x faster embedding generation!

---

## ğŸ¤– MCP Server (Cursor Integration)

Connect KSdb to Cursor AI:

```bash
# Start MCP server
python -m ksdb.mcp_server
```

Add to Cursor's `mcp_settings.json`:
```json
{
  "mcpServers": {
    "ksdb": {
      "command": "python",
      "args": ["-m", "ksdb.mcp_server"]
    }
  }
}
```

Now Cursor can search your documents!

---

## â˜ï¸ Deployment

### Local (SQLite)
```bash
python -m ksdb.cli run
```

### Docker
```bash
docker-compose up
```

### Production (AWS)
See [deployment.md](deployment.md) for AWS setup.

---

## ğŸ“ˆ Performance Optimizations

**Quick Wins:**
1. Disable graph extraction if not needed: `extract_graph=False` (8.9x faster)
2. Use batch ingestion: 100-500 docs at once
3. Enable GPU acceleration (already automatic)

**Advanced:**
- Query caching (10-100x faster for repeated queries)
- Custom HNSW parameters (M=32, ef=400)
- Async operations for background processing

See `performance_analysis.py` for details.

---

## ğŸ›£ï¸ Roadmap

- [x] Hybrid Search (Vector + Keyword)
- [x] Knowledge Graph Extraction
- [x] GPU Acceleration
- [x] OCR Support
- [x] MCP Server
- [x] Streamlit Demo
- [ ] **Authentication** (API keys)
- [ ] **Batch API** (10x faster bulk inserts)
- [ ] **Web Dashboard** (visual interface)
- [ ] **LangChain Integration** (official)
- [ ] **Multi-node Scaling** (horizontal scaling)

---

## ğŸ¤ Contributing

We welcome contributions! Areas we need help:
- ğŸš€ Performance optimization
- ğŸ” Authentication & security
- ğŸ“Š Advanced query features
- ğŸ¨ Web dashboard
- ğŸ“š Documentation & tutorials

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

Built with:
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [HNSWlib](https://github.com/nmslib/hnswlib) - Fast vector search
- [Sentence Transformers](https://www.sbert.net/) - Text embeddings
- [GLiNER](https://github.com/urchade/GLiNER) - Entity extraction
- [EasyOCR](https://github.com/JaidedAI/EasyOCR) - OCR support

---

<div align="center">

**â­ Star this repo if you find it useful!**

Made with â¤ï¸ by [Kulraj Singh](https://github.com/Kulraj69)

</div>
